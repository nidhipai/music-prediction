{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uH9-Bl6HP-Bq"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NulWEff5qVyj",
        "outputId": "19bd79d2-620d-4a48-d0ee-ff3a4eef212e"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/ageron/handson-ml2/raw/master/datasets/jsb_chorales/jsb_chorales.tgz\n",
        "!tar xzvf jsb_chorales.tgz\n",
        "!pip install midiutil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhfPXjP5QExK"
      },
      "source": [
        "Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnWULkfzq8Si"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "TRAIN_FOLDER = \"train\"\n",
        "TEST_FOLDER = \"test\"\n",
        "VALIDATION_FOLDER = \"valid\"\n",
        "\n",
        "file_list = [os.path.join(TRAIN_FOLDER, x) for x in os.listdir(TRAIN_FOLDER)]\\\n",
        " + [os.path.join(TEST_FOLDER, x) for x in os.listdir(TEST_FOLDER)]\\\n",
        " + [os.path.join(VALIDATION_FOLDER, x) for x in os.listdir(VALIDATION_FOLDER)]\n",
        "\n",
        "notes_data = [pd.read_csv(curr_file).to_numpy() for curr_file in file_list]\n",
        "longest_music_length = max([curr_data.shape[0] for curr_data in notes_data])\n",
        "final_notes_data = np.zeros((len(notes_data), longest_music_length, notes_data[0].shape[1]))\n",
        "for idx, curr_note_data in enumerate(notes_data):\n",
        "    final_notes_data[idx, :curr_note_data.shape[0], :] = curr_note_data\n",
        "final_notes_data = torch.tensor(final_notes_data, dtype=torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QkzUbUo79F-"
      },
      "outputs": [],
      "source": [
        "max_val = final_notes_data.max()\n",
        "final_notes_data /= max_val\n",
        "lowest_val = final_notes_data.reshape([1, 1, final_notes_data.shape[0] * final_notes_data.shape[1] * final_notes_data.shape[2]]).unique().kthvalue(2)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gp9FbG3TQJw6"
      },
      "source": [
        "# LSTM Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6KM3ysXtSCb"
      },
      "outputs": [],
      "source": [
        "from torch import nn, optim\n",
        "import torch\n",
        "\n",
        "\n",
        "class MusicNet(nn.Module):\n",
        "    def __init__(self, input_size=4, hidden_size=100, num_layers=1, dropout=0.1) -> None:\n",
        "        super().__init__()\n",
        "        self.hidden = [None, None]\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, dropout=dropout, batch_first=True)\n",
        "        self.lin1 = nn.Linear(hidden_size, hidden_size) # Input Size = Output input_size\n",
        "        self.relu = nn.ReLU()\n",
        "        self.lin2 = nn.Linear(hidden_size, input_size)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        ini1, self.hidden = self.lstm(x) if self.hidden[0] is None else self.lstm(x, self.hidden)\n",
        "        if torch.nan in ini1:\n",
        "            print(\"AHHH!\")\n",
        "        return self.relu(self.lin2(self.relu(self.lin1(ini1))))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVLwgIJeve7U",
        "outputId": "78632079-f885-4c50-a32a-4ee68622a94c"
      },
      "outputs": [],
      "source": [
        "model = MusicNet(hidden_size=10)\n",
        "criterion = nn.L1Loss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9gSXSgvu-jC",
        "outputId": "63599ff8-da5e-447b-b241-4cf64530d1e1"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tqdm import trange\n",
        "\n",
        "\n",
        "MAX_TRAIN_INPUT = 32\n",
        "NUM_EPOCHS = 20\n",
        "MAX_BATCH_SIZE = 1\n",
        "curr_data = final_notes_data[:MAX_BATCH_SIZE, :, :]\n",
        "target = curr_data[:, MAX_TRAIN_INPUT:, :]\n",
        "last_loss = None\n",
        "\n",
        "with trange(NUM_EPOCHS, position=0) as progress_bar:\n",
        "    for _ in progress_bar:\n",
        "        pred = torch.zeros(target.shape)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        last_slice_idx = curr_data.shape[1] - MAX_TRAIN_INPUT\n",
        "        for i in range(last_slice_idx):\n",
        "            curr_segment = curr_data[:, i: i + MAX_TRAIN_INPUT, :]\n",
        "            predicted_notes = model(curr_segment)\n",
        "            pred[:, i, :] = predicted_notes[:, 0, :]\n",
        "            progress_bar.set_postfix(loss=last_loss, itr=f\"{i}/{last_slice_idx}\")\n",
        "        loss = criterion(target, pred)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        model.hidden = [None, None]\n",
        "\n",
        "        last_loss = float(loss.data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Music Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2XwrIfAFmvl"
      },
      "outputs": [],
      "source": [
        "music_input = final_notes_data[MAX_BATCH_SIZE, :MAX_TRAIN_INPUT, :].unsqueeze(dim=0)\n",
        "pred = torch.zeros([1, final_notes_data.shape[1], final_notes_data.shape[2]])\n",
        "pred[:, :MAX_TRAIN_INPUT, :] = music_input\n",
        "last_slice_idx = pred.shape[1] - MAX_TRAIN_INPUT\n",
        "\n",
        "for i in range(last_slice_idx):\n",
        "    curr_slice = pred[:, i: i + MAX_TRAIN_INPUT, :]\n",
        "    predicted_notes = model(curr_slice)\n",
        "    pred[:, i + MAX_TRAIN_INPUT, :] = predicted_notes[:, 0, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50Awsn-PSePD"
      },
      "outputs": [],
      "source": [
        "pred[pred > 1] = 1\n",
        "lowest_val = final_notes_data.reshape([1, 1, final_notes_data.shape[0] * final_notes_data.shape[1] * final_notes_data.shape[2]]).unique().kthvalue(2)[0]\n",
        "pred[pred < lowest_val / 2] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZIMUyrm11Rk"
      },
      "outputs": [],
      "source": [
        "pred *= max_val\n",
        "pred = torch.round(pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feed Forward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch import nn, optim\n",
        "import torch\n",
        "\n",
        "class LinearMusicNet(nn.Module):\n",
        "    def __init__(self, input_size=4, hidden_size=100) -> None:\n",
        "        super().__init__()\n",
        "        self.lin1 = nn.Linear(input_size, hidden_size)\n",
        "        self.lin2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.lin3 = nn.Linear(hidden_size, input_size)\n",
        "        self.relu = nn.ReLU()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.relu(self.lin3(self.relu(self.lin2(self.relu(self.lin1(x))))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = LinearMusicNet(hidden_size=10)\n",
        "criterion = nn.L1Loss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import trange\n",
        "\n",
        "\n",
        "MAX_TRAIN_INPUT = 32\n",
        "NUM_EPOCHS = 20\n",
        "MAX_BATCH_SIZE = 1\n",
        "curr_data = final_notes_data[:MAX_BATCH_SIZE, :, :]\n",
        "target = curr_data[:, MAX_TRAIN_INPUT:, :]\n",
        "last_loss = None\n",
        "\n",
        "with trange(NUM_EPOCHS, position=0) as progress_bar:\n",
        "    for _ in progress_bar:\n",
        "        pred = torch.zeros(target.shape)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        last_slice_idx = curr_data.shape[1] - MAX_TRAIN_INPUT\n",
        "        for i in range(last_slice_idx):\n",
        "            curr_segment = curr_data[:, i: i + MAX_TRAIN_INPUT, :]\n",
        "            predicted_notes = model(curr_segment)\n",
        "            print(predicted_notes.shape)\n",
        "            pred[:, i, :] = predicted_notes[:, 0, :]\n",
        "            progress_bar.set_postfix(loss=last_loss, itr=f\"{i}/{last_slice_idx}\")\n",
        "\n",
        "        loss = criterion(target, pred)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        model.hidden = [None, None]\n",
        "\n",
        "        last_loss = float(loss.data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Music Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "music_input = final_notes_data[MAX_BATCH_SIZE, :MAX_TRAIN_INPUT, :].unsqueeze(dim=0)\n",
        "pred = torch.zeros([1, final_notes_data.shape[1], final_notes_data.shape[2]])\n",
        "pred[:, :MAX_TRAIN_INPUT, :] = music_input\n",
        "last_slice_idx = pred.shape[1] - MAX_TRAIN_INPUT\n",
        "\n",
        "for i in range(last_slice_idx):\n",
        "    curr_slice = pred[:, i: i + MAX_TRAIN_INPUT, :]\n",
        "    predicted_notes = model(curr_slice)\n",
        "    pred[:, i + MAX_TRAIN_INPUT, :] = predicted_notes[:, 0, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50Awsn-PSePD"
      },
      "outputs": [],
      "source": [
        "pred[pred > 1] = 1\n",
        "lowest_val = final_notes_data.reshape([1, 1, final_notes_data.shape[0] * final_notes_data.shape[1] * final_notes_data.shape[2]]).unique().kthvalue(2)[0]\n",
        "pred[pred < lowest_val / 2] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZIMUyrm11Rk"
      },
      "outputs": [],
      "source": [
        "pred *= max_val\n",
        "pred = torch.round(pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Simple RNN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch import nn, optim\n",
        "import torch\n",
        "\n",
        "class RnnMusicNet(nn.Module):\n",
        "    def __init__(self, input_size=4, hidden_size=100, num_layers=2, dropout=0.1) -> None:\n",
        "        super().__init__()\n",
        "        self.hidden = [None, None]\n",
        "        self.rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, dropout=dropout, batch_first=True)\n",
        "        self.lin1 = nn.Linear(hidden_size, hidden_size) # Input Size = Output input_size\n",
        "        self.relu = nn.ReLU()\n",
        "        self.lin2 = nn.Linear(hidden_size, input_size)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        ini1, self.hidden = self.rnn(x) if self.hidden[0] is None else self.rnn(x, self.hidden)\n",
        "        return self.relu(self.lin2(self.relu(self.lin1(ini1))))\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = RnnMusicNet(hidden_size=10)\n",
        "criterion = nn.L1Loss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:20<00:00,  1.04s/it, itr=607/608, loss=0.079]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import trange\n",
        "\n",
        "\n",
        "MAX_TRAIN_INPUT = 32\n",
        "NUM_EPOCHS = 20\n",
        "MAX_BATCH_SIZE = 1\n",
        "curr_data = final_notes_data[:MAX_BATCH_SIZE, :, :]\n",
        "target = curr_data[:, MAX_TRAIN_INPUT:, :]\n",
        "last_loss = None\n",
        "\n",
        "with trange(NUM_EPOCHS, position=0) as progress_bar:\n",
        "    for _ in progress_bar:\n",
        "        pred = torch.zeros(target.shape)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        last_slice_idx = curr_data.shape[1] - MAX_TRAIN_INPUT\n",
        "        for i in range(last_slice_idx):\n",
        "            curr_segment = curr_data[:, i: i + MAX_TRAIN_INPUT, :]\n",
        "            predicted_notes = model(curr_segment)\n",
        "            pred[:, i, :] = predicted_notes[:, 0, :]\n",
        "            progress_bar.set_postfix(loss=last_loss, itr=f\"{i}/{last_slice_idx}\")\n",
        "\n",
        "        loss = criterion(target, pred)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        model.hidden = [None, None]\n",
        "\n",
        "        last_loss = float(loss.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Music Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "music_input = final_notes_data[MAX_BATCH_SIZE, :MAX_TRAIN_INPUT, :].unsqueeze(dim=0)\n",
        "pred = torch.zeros([1, final_notes_data.shape[1], final_notes_data.shape[2]])\n",
        "pred[:, :MAX_TRAIN_INPUT, :] = music_input\n",
        "last_slice_idx = pred.shape[1] - MAX_TRAIN_INPUT\n",
        "\n",
        "for i in range(last_slice_idx):\n",
        "    curr_slice = pred[:, i: i + MAX_TRAIN_INPUT, :]\n",
        "    predicted_notes = model(curr_slice)\n",
        "    pred[:, i + MAX_TRAIN_INPUT, :] = predicted_notes[:, 0, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred[pred > 1] = 1\n",
        "lowest_val = final_notes_data.reshape([1, 1, final_notes_data.shape[0] * final_notes_data.shape[1] * final_notes_data.shape[2]]).unique().kthvalue(2)[0]\n",
        "pred[pred < lowest_val / 2] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred *= max_val\n",
        "pred = torch.round(pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_FtQzTQQcEJ"
      },
      "source": [
        "## Generate a MIDI File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "SxALh3h16ck7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[64. 64. 64. 64. 64. 64. 64. 64. 64. 64. 64. 64. 71. 71. 71. 71. 71. 71.\n",
            " 71. 71. 71. 71. 71. 71. 69. 69. 69. 69. 71. 71. 71. 71. 55. 79. 78. 79.\n",
            " 79. 79. 79. 79. 78. 79. 78. 79. 79. 78. 79. 79. 78. 79. 78. 78. 79. 78.\n",
            " 79. 78. 79. 79. 78. 79. 79. 76. 79. 78. 79. 76. 78. 78. 77. 79. 79. 79.\n",
            " 79. 79. 78. 78. 78. 79. 78. 79. 78. 79. 79. 79. 79. 79. 79. 79. 79. 78.\n",
            " 79. 77. 79. 79. 79. 79. 79. 79. 74. 78. 78. 79. 79. 76. 78. 79. 78. 79.\n",
            " 78. 79. 79. 79. 77. 78. 79. 79. 79. 78. 79. 79. 79. 78. 79. 79. 78. 79.\n",
            " 79. 79. 78. 77. 79. 79. 79. 76. 77. 78. 79. 79. 78. 79. 79. 79. 79. 79.\n",
            " 79. 76. 79. 79. 79. 79. 79. 78. 79. 79. 79. 79. 78. 79. 79. 78. 79. 79.\n",
            " 78. 78. 79. 79. 80. 79. 78. 79. 78. 79. 78. 78. 79. 79. 79. 77. 79. 78.\n",
            " 79. 79. 79. 78. 78. 78. 79. 79. 79. 79. 76. 79. 77. 79. 78. 79. 79. 79.\n",
            " 79. 79. 78. 79. 77. 78. 79. 80. 79. 76. 78. 78. 78. 79. 79. 79. 78. 79.\n",
            " 79. 79. 79. 79. 78. 78. 79. 79. 79. 78. 79. 79. 79. 76. 78. 78. 79. 79.\n",
            " 79. 79. 79. 79. 78. 79. 79. 78. 79. 78. 79. 79. 79. 79. 79. 79. 79. 77.\n",
            " 77. 79. 76. 78. 79. 79. 79. 79. 77. 79. 79. 79. 79. 79. 79. 79. 76. 79.\n",
            " 78. 79. 79. 77. 77. 79. 78. 79. 78. 79. 74. 78. 78. 78. 79. 78. 78. 79.\n",
            " 79. 79. 79. 79. 79. 79. 79. 79. 79. 79. 79. 79. 78. 79. 79. 79. 79. 79.\n",
            " 78. 78. 79. 79. 78. 78. 77. 79. 79. 79. 79. 78. 78. 78. 79. 79. 79. 79.\n",
            " 79. 78. 79. 78. 79. 78. 76. 79. 79. 79. 76. 78. 79. 78. 79. 76. 79. 79.\n",
            " 78. 78. 78. 79. 78. 78. 78. 79. 78. 79. 76. 79. 79. 79. 78. 79. 78. 77.\n",
            " 74. 79. 79. 77. 76. 78. 78. 79. 77. 79. 78. 79. 78. 79. 79. 77. 79. 78.\n",
            " 78. 79. 77. 79. 79. 79. 79. 79. 78. 78. 79. 79. 79. 78. 78. 78. 79. 79.\n",
            " 78. 79. 79. 79. 79. 79. 78. 78. 79. 79. 79. 78. 79. 79. 79. 79. 78. 77.\n",
            " 78. 78. 78. 78. 79. 77. 79. 79. 79. 79. 79. 79. 79. 79. 79. 78. 79. 79.\n",
            " 78. 79. 79. 79. 77. 79. 78. 78. 78. 78. 78. 78. 79. 78. 78. 77. 79. 79.\n",
            " 79. 78. 77. 78. 79. 78. 79. 79. 79. 77. 78. 79. 79. 79. 79. 76. 78. 76.\n",
            " 78. 79. 79. 79. 79. 78. 78. 79. 79. 79. 79. 77. 79. 79. 78. 78. 79. 79.\n",
            " 78. 79. 79. 78. 78. 77. 79. 78. 79. 78. 77. 78. 78. 79. 79. 79. 79. 79.\n",
            " 77. 79. 79. 79. 79. 76. 79. 79. 78. 78. 79. 78. 78. 79. 79. 76. 76. 78.\n",
            " 78. 78. 79. 76. 79. 79. 79. 78. 79. 79. 79. 78. 78. 78. 79. 78. 79. 78.\n",
            " 79. 79. 78. 79. 78. 79. 79. 78. 79. 78. 79. 79. 79. 79. 79. 76. 79. 79.\n",
            " 78. 78. 79. 79. 79. 79. 78. 76. 78. 79. 79. 76. 79. 79. 79. 79. 79. 79.\n",
            " 77. 79. 78. 79. 79. 79. 79. 76. 79. 78. 77. 79. 79. 79. 76. 78. 78. 79.\n",
            " 77. 79. 79. 79. 79. 79. 78. 79. 79. 79. 79. 78. 78. 76. 78. 79. 78. 79.\n",
            " 78. 79. 79. 79. 79. 79. 77. 78. 79. 78. 79. 78. 79. 78. 78. 79. 79. 79.\n",
            " 78. 78. 79. 79. 79. 79. 79. 79. 79. 79.]\n",
            "[59. 59. 59. 59. 59. 59. 59. 59. 59. 59. 59. 59. 66. 66. 66. 66. 66. 66.\n",
            " 66. 66. 67. 67. 67. 67. 67. 67. 67. 67. 66. 66. 66. 66. 52. 77. 76. 77.\n",
            " 77. 77. 77. 77. 77. 77. 77. 76. 77. 77. 77. 76. 76. 77. 76. 76. 77. 76.\n",
            " 77. 77. 77. 76. 76. 77. 77. 76. 77. 77. 76. 73. 77. 76. 77. 77. 77. 77.\n",
            " 77. 76. 77. 76. 76. 77. 76. 77. 77. 77. 77. 77. 77. 77. 77. 76. 76. 75.\n",
            " 77. 75. 77. 77. 75. 77. 77. 77. 74. 77. 77. 77. 77. 75. 77. 77. 76. 77.\n",
            " 76. 77. 77. 77. 77. 77. 77. 77. 77. 76. 77. 77. 77. 76. 76. 77. 77. 77.\n",
            " 77. 77. 76. 75. 77. 77. 76. 74. 75. 76. 76. 76. 75. 77. 77. 76. 77. 77.\n",
            " 76. 75. 76. 77. 77. 76. 77. 77. 77. 77. 77. 77. 77. 77. 77. 76. 77. 76.\n",
            " 76. 76. 77. 77. 75. 77. 76. 76. 76. 77. 77. 77. 77. 76. 77. 74. 77. 74.\n",
            " 77. 77. 77. 75. 76. 76. 77. 75. 77. 77. 74. 77. 76. 77. 76. 77. 77. 77.\n",
            " 77. 77. 77. 77. 77. 77. 77. 75. 77. 75. 76. 76. 76. 77. 77. 76. 75. 77.\n",
            " 77. 77. 77. 77. 77. 76. 77. 76. 77. 76. 77. 77. 77. 74. 76. 75. 77. 77.\n",
            " 77. 76. 75. 77. 76. 77. 77. 76. 77. 76. 77. 77. 76. 77. 77. 76. 77. 76.\n",
            " 76. 76. 74. 76. 76. 76. 77. 77. 77. 77. 76. 77. 77. 77. 77. 77. 75. 76.\n",
            " 75. 77. 76. 75. 75. 77. 76. 76. 76. 76. 74. 76. 76. 77. 77. 76. 77. 77.\n",
            " 77. 77. 77. 77. 77. 77. 77. 75. 77. 77. 77. 77. 77. 75. 77. 77. 77. 77.\n",
            " 76. 77. 76. 76. 77. 76. 77. 77. 77. 77. 77. 77. 76. 75. 76. 77. 76. 77.\n",
            " 77. 76. 77. 76. 77. 75. 76. 77. 77. 77. 75. 77. 77. 76. 76. 75. 77. 77.\n",
            " 76. 76. 76. 77. 77. 77. 76. 76. 74. 77. 74. 77. 77. 77. 76. 77. 76. 76.\n",
            " 72. 77. 76. 76. 75. 76. 76. 77. 77. 76. 76. 76. 76. 77. 76. 74. 77. 76.\n",
            " 77. 77. 75. 76. 77. 77. 77. 77. 76. 75. 77. 77. 77. 76. 77. 76. 76. 77.\n",
            " 77. 77. 77. 77. 77. 77. 76. 76. 77. 77. 76. 76. 77. 75. 76. 77. 74. 75.\n",
            " 76. 76. 76. 76. 77. 77. 77. 77. 75. 77. 77. 76. 77. 76. 77. 77. 76. 77.\n",
            " 77. 76. 77. 77. 73. 77. 76. 76. 76. 77. 76. 77. 77. 75. 75. 75. 77. 77.\n",
            " 76. 77. 77. 77. 77. 76. 76. 77. 77. 75. 75. 77. 77. 77. 77. 73. 77. 74.\n",
            " 76. 77. 77. 76. 77. 77. 74. 77. 77. 77. 77. 77. 77. 77. 76. 76. 77. 77.\n",
            " 77. 77. 77. 76. 76. 76. 77. 73. 77. 77. 74. 76. 76. 77. 77. 77. 77. 77.\n",
            " 75. 77. 76. 76. 77. 75. 77. 77. 76. 76. 77. 76. 76. 77. 77. 75. 75. 74.\n",
            " 76. 76. 76. 71. 76. 76. 77. 77. 76. 76. 77. 76. 77. 76. 77. 76. 77. 77.\n",
            " 77. 77. 75. 77. 76. 77. 76. 77. 77. 76. 77. 77. 76. 77. 77. 74. 76. 76.\n",
            " 77. 77. 77. 77. 77. 76. 76. 75. 77. 77. 77. 73. 77. 75. 77. 77. 77. 76.\n",
            " 76. 77. 77. 76. 77. 77. 77. 75. 75. 76. 76. 77. 77. 77. 73. 76. 76. 77.\n",
            " 74. 77. 77. 77. 77. 77. 77. 77. 77. 77. 76. 77. 77. 75. 76. 77. 75. 77.\n",
            " 77. 77. 77. 77. 77. 77. 77. 76. 76. 76. 77. 74. 77. 75. 76. 77. 77. 77.\n",
            " 76. 76. 77. 77. 77. 76. 77. 77. 77. 76.]\n",
            "[55. 55. 55. 55. 55. 55. 55. 55. 55. 55. 55. 55. 54. 54. 54. 54. 63. 63.\n",
            " 63. 63. 64. 64. 64. 64. 64. 64. 64. 64. 59. 59. 59. 59. 44. 72. 71. 72.\n",
            " 72. 72. 72. 72. 71. 72. 71. 71. 72. 72. 72. 71. 71. 72. 71. 71. 72. 71.\n",
            " 72. 72. 72. 71. 71. 72. 72. 70. 72. 71. 71. 67. 72. 70. 71. 72. 72. 72.\n",
            " 72. 71. 71. 71. 71. 72. 71. 72. 72. 72. 72. 72. 72. 72. 72. 71. 71. 71.\n",
            " 72. 70. 72. 72. 69. 72. 72. 72. 68. 72. 71. 72. 72. 69. 71. 72. 70. 72.\n",
            " 71. 72. 72. 72. 71. 71. 72. 72. 72. 71. 72. 72. 72. 71. 71. 72. 72. 72.\n",
            " 72. 72. 71. 70. 72. 72. 71. 69. 70. 71. 71. 71. 70. 72. 72. 71. 72. 72.\n",
            " 71. 69. 71. 72. 72. 71. 72. 72. 72. 72. 72. 72. 72. 72. 72. 71. 72. 71.\n",
            " 71. 71. 72. 72. 70. 72. 71. 71. 71. 72. 71. 72. 72. 71. 72. 69. 72. 69.\n",
            " 72. 72. 72. 69. 71. 71. 72. 69. 72. 72. 69. 72. 71. 72. 70. 72. 72. 72.\n",
            " 72. 72. 72. 72. 71. 72. 72. 70. 72. 69. 71. 71. 70. 72. 72. 71. 70. 72.\n",
            " 72. 72. 72. 72. 72. 71. 72. 71. 72. 71. 72. 72. 72. 68. 71. 70. 72. 72.\n",
            " 72. 71. 70. 72. 71. 72. 71. 70. 72. 71. 72. 72. 71. 72. 72. 71. 72. 71.\n",
            " 70. 71. 68. 71. 71. 71. 72. 72. 71. 72. 71. 72. 72. 72. 72. 72. 70. 71.\n",
            " 70. 72. 71. 70. 70. 72. 70. 71. 71. 71. 68. 71. 70. 72. 72. 71. 72. 72.\n",
            " 72. 72. 72. 72. 72. 72. 72. 69. 72. 72. 72. 72. 72. 70. 72. 72. 72. 72.\n",
            " 71. 72. 71. 71. 72. 71. 71. 72. 72. 72. 72. 72. 71. 70. 71. 72. 71. 72.\n",
            " 72. 71. 72. 71. 72. 70. 69. 72. 72. 72. 69. 72. 72. 71. 71. 69. 72. 72.\n",
            " 71. 71. 70. 72. 72. 72. 71. 71. 70. 72. 69. 72. 72. 72. 71. 72. 71. 71.\n",
            " 66. 72. 71. 71. 69. 71. 71. 72. 71. 71. 71. 71. 71. 72. 71. 68. 72. 71.\n",
            " 71. 72. 70. 71. 72. 72. 72. 72. 71. 70. 72. 72. 72. 71. 72. 71. 71. 72.\n",
            " 72. 72. 72. 72. 72. 72. 71. 71. 72. 72. 71. 71. 72. 69. 71. 72. 69. 70.\n",
            " 71. 71. 71. 71. 72. 71. 72. 72. 70. 72. 72. 71. 72. 71. 72. 72. 71. 72.\n",
            " 71. 71. 72. 72. 68. 72. 71. 70. 71. 71. 71. 72. 72. 70. 70. 70. 72. 72.\n",
            " 71. 71. 71. 72. 72. 71. 71. 72. 72. 69. 70. 72. 72. 72. 72. 68. 72. 68.\n",
            " 70. 72. 71. 71. 72. 72. 69. 72. 72. 72. 72. 71. 72. 72. 71. 71. 72. 72.\n",
            " 72. 72. 72. 70. 71. 71. 72. 68. 72. 71. 69. 70. 71. 72. 72. 72. 72. 72.\n",
            " 70. 72. 71. 71. 72. 69. 72. 72. 71. 71. 72. 71. 71. 72. 72. 70. 70. 69.\n",
            " 71. 70. 71. 66. 71. 71. 72. 71. 71. 71. 72. 70. 72. 70. 72. 71. 72. 71.\n",
            " 72. 72. 70. 72. 71. 72. 71. 71. 72. 71. 72. 72. 71. 72. 72. 69. 71. 71.\n",
            " 72. 72. 72. 72. 72. 71. 71. 70. 72. 72. 72. 68. 72. 69. 72. 72. 72. 71.\n",
            " 70. 72. 72. 71. 72. 72. 72. 69. 69. 70. 70. 72. 72. 72. 68. 71. 71. 72.\n",
            " 69. 72. 72. 72. 72. 72. 71. 72. 72. 72. 71. 71. 72. 70. 71. 72. 70. 72.\n",
            " 72. 72. 72. 72. 72. 72. 71. 70. 71. 70. 72. 70. 72. 70. 71. 72. 72. 72.\n",
            " 70. 71. 72. 72. 72. 71. 72. 72. 72. 71.]\n",
            "[52. 52. 52. 52. 55. 55. 55. 55. 52. 52. 52. 52. 51. 51. 51. 51. 47. 47.\n",
            " 47. 47. 52. 52. 52. 52. 49. 49. 49. 49. 51. 51. 51. 51.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
          ]
        }
      ],
      "source": [
        "from midiutil import MIDIFile\n",
        "\n",
        "degrees  = [60, 62, 64, 65, 67, 69, 71, 72]  # MIDI note number\n",
        "track    = 0\n",
        "channel  = 0\n",
        "time     = 0    # In beats\n",
        "duration = 1    # In beats\n",
        "tempo    = 60   # In BPM\n",
        "volume   = 100  # 0-127, as per the MIDI standard\n",
        "\n",
        "MyMIDI = MIDIFile(1)  # One track\n",
        "MyMIDI.addTempo(track, time, tempo)\n",
        "\n",
        "numpy_vals = pred.detach().numpy()[0, :, :]\n",
        "\n",
        "for curr_channel in range(numpy_vals.shape[1]):\n",
        "    print(numpy_vals[:, curr_channel])\n",
        "    for i, pitch in enumerate(numpy_vals[:, curr_channel].tolist()):\n",
        "        # print(pitch)\n",
        "        if pitch != 0:\n",
        "            MyMIDI.addNote(track, curr_channel, int(pitch), time + i, duration, volume)\n",
        "\n",
        "with open(\"test-file.mid\", \"wb\") as output_file:\n",
        "    MyMIDI.writeFile(output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Music Generation Thingy",
      "provenance": []
    },
    "interpreter": {
      "hash": "c59643840aeeee69b70a6e3ce381fb18b881a964938277a977cdf58318ef8b41"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit ('vip': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
